{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular generation conditioned on per-SMILES median profiles from different clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity (tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format ='%(levelname)s - %(message)s')\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Descriptors import qed\n",
    "import sys\n",
    "sys.path.append(os.path.join(Chem.RDConfig.RDContribDir, 'SA_Score'))\n",
    "import sascorer\n",
    "\n",
    "import cpmolgan.utils as utils\n",
    "import cpmolgan.inference as infr\n",
    "import pkg_resources\n",
    "WEIGHTS_PATH = pkg_resources.resource_filename('cpmolgan','model_weights')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"N_valid_per_cluster\":15000,\n",
    "    'use_gpu': True,\n",
    "    'gpu_device':'1',\n",
    "    'filename_train_profiles':\"results/train_set_cluster_profiles_median_per_smiles.csv\",\n",
    "    \"output_dir\":\"results/generated_mols/\",\n",
    "    \"clusters\":['Cluster'+str(c) for c in range(20)][0:1]\n",
    "}\n",
    "\n",
    "if not os.path.isdir(args[\"output_dir\"]):\n",
    "    os.makedirs(args[\"output_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set compute environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['use_gpu']:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args['gpu_device']\n",
    "    gpu_options = tf.GPUOptions(visible_device_list='0')\n",
    "    tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    tf.config.set_soft_device_placement(True)\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## 2. Load inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_weigth_paths = {\n",
    "    'autoencoder': os.path.join(WEIGHTS_PATH,'autoencoder.h5'),\n",
    "    'wgan':{\n",
    "            'C': os.path.join(WEIGHTS_PATH,'gan_C.h5'),\n",
    "            'D': os.path.join(WEIGHTS_PATH,'gan_D.h5'),\n",
    "            'G': os.path.join(WEIGHTS_PATH,'gan_G.h5'),\n",
    "            'condition_encoder':os.path.join(WEIGHTS_PATH,'gan_condition_encoder.h5'),\n",
    "            'classifier':os.path.join(WEIGHTS_PATH,'gan_classifier.h5')\n",
    "            }\n",
    "}\n",
    "\n",
    "model = infr.InferenceModel( model_weigth_paths ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read profiles and apply quantile transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Number of clusters: 1\n",
      "INFO - clusters: array(['Cluster0'], dtype=object)\n",
      "INFO - Number of Morphological profiles: 2707\n"
     ]
    }
   ],
   "source": [
    "# Read data and select specified clusters\n",
    "data_train = pd.read_csv(args['filename_train_profiles'], index_col=0 )\n",
    "keep_idx = data_train.cluster.isin(args[\"clusters\"])\n",
    "data_train = data_train[keep_idx].reset_index(drop=True)\n",
    "logging.info('Number of clusters: %i'%len(data_train.cluster.unique()))\n",
    "logging.info('clusters: %a'%data_train.cluster.unique())\n",
    "\n",
    "# Apply quantile transformer\n",
    "quantile_transformer =  pickle.load( open( os.path.join(WEIGHTS_PATH,'quantile_transformer.pkl'), 'rb' ) )\n",
    "feature_cols , info_cols = utils.get_feature_cols(data_train)\n",
    "data_train[feature_cols] = quantile_transformer.transform(data_train[feature_cols].values)   \n",
    "logging.info('Number of Morphological profiles: %i'%data_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate a fixed number of valid molecules per gene\n",
    "We dont want to filter unique here, because the frequency in which a molecule is generated also provides information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ------ Cluster0 ---------\n",
      "INFO - results/generated_mols/Cluster0__15000_Valid.csv\n",
      "WARNING - File results/generated_mols/Cluster0__15000_Valid.csv already exists. Skipping it \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cluster in args[\"clusters\"]:\n",
    "    \n",
    "    logging.info(\"------ %s ---------\"%cluster)\n",
    "    \n",
    "    # Define output file and check that it doesn't already exit\n",
    "    output_file = os.path.join(args[\"output_dir\"], cluster+\"__\"+str(args[\"N_valid_per_cluster\"])+\"_Valid.csv\")\n",
    "    logging.info(output_file)\n",
    "    if os.path.isfile(output_file):\n",
    "        logging.warning(\"File %s already exists. Skipping it \\n\"%output_file)\n",
    "        continue\n",
    "    \n",
    "    # Generate a fixed amount of molecules per cluster\n",
    "    cluster_idx = data_train[\"cluster\"] == cluster\n",
    "    cluster_data = data_train.loc[cluster_idx].reset_index(drop=True)\n",
    "    N = len(cluster_data)\n",
    "    generated_final = pd.DataFrame()\n",
    "    i = 0    \n",
    "    \n",
    "    # Adjust the number of generated molecules per condition according to the number of available samples\n",
    "    max_Nconditions = 500\n",
    "    sample_cluster_data = False\n",
    "    if len(cluster_data) > max_Nconditions:\n",
    "        sample_cluster_data = True\n",
    "    if N/args[\"N_valid_per_cluster\"] < 1e-2:\n",
    "        N_per_condition = 100  \n",
    "    else:\n",
    "        N_per_condition = 10\n",
    "            \n",
    "    while len(generated_final) < args[\"N_valid_per_cluster\"]:\n",
    "        \n",
    "        if sample_cluster_data:\n",
    "            cluster_data = data_train.loc[cluster_idx].sample(max_Nconditions, random_state=0).reset_index(drop=True)\n",
    "        \n",
    "        # Run generation and filter valid and unique inside current generated batch \n",
    "        temp_generated = infr.generate_compounds_multiple_conditions( model, cluster_data, feature_cols, info_cols, seed=0, nsamples=N_per_condition)\n",
    "        temp_generated = infr.filter_valid_and_unique(temp_generated, cond_ID_cols=[\"cluster\"], select_unique=False)\n",
    "        generated_final = pd.concat([generated_final, temp_generated])\n",
    "        logging.info(\"%s iteration %i: %i valid molecules \"%(cluster,i,len(generated_final)) )\n",
    "        i = i +1\n",
    "        \n",
    "    # Save results\n",
    "    generated_final = generated_final.reset_index(drop=True)\n",
    "    generated_final = generated_final.iloc[0:args[\"N_valid_per_cluster\"]]\n",
    "    generated_final.to_csv(output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('cpmolgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c523d9eda279fa4bb4f5cb4e0f9aaca1b2e33fee79d53bba9fa5bcd6fe7fb4f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
