{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform several scaffold analyses on generated molecules conditioned on profiles from selected genes and DMSO\n",
    "- Quantify common scaffolds between generated molecules and agonists from the ExCAPE Database:  \n",
    "`common_MurkoScafold_quantification_Gene_vs_Excape_mean.csv'`\n",
    "- Perform scaffold enrichment analysis of generated molecules conditioned on each gene vs DMSO, and select large scaffolds consistently enriched in 3 repetitions:   \n",
    "`LargeConsistentlyEnrichedScafolds.pkl`\n",
    "- Collect ExCAPE molecules containing enriched scaffolds (ExCAPE hits)\n",
    "`Excape_agonists_with_LargeConsistentlyEnrichedScafolds`\n",
    "- Collect generated molecules with enriched scaffolds and high similarity to ExCAPE hits  \n",
    "`GeneratedMols_with_LargeConsistentlyEnrichedScafolds_and_HighExcapeSim__...`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from rdkit.Chem import PandasTools\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import logging \n",
    "logging.basicConfig(level=logging.INFO, format ='%(levelname)s - %(message)s')\n",
    "\n",
    "import cpmolgan.utils as utils\n",
    "import cpmolgan.nearest_neighbors as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'p-value': 0.01, \n",
    "    'ecfp_sim_thresh':0.6,\n",
    "    'filename_data_Excape':'../../data/ExCAPE_ligands_agonist_noTrainSet.csv',\n",
    "    'results_dir': 'results',\n",
    "    'generated_ref_dir':\"REP_Valid_PassPhysChemFilter/generated_mols\",\n",
    "    'generated_ref_filename':\"GENE__20000_Valid_PassPhysChemFilter.csv\",\n",
    "    'repetitions': [\"n1\",\"n2\",\"n3\"],\n",
    "    'Excape_genes':[\"TP53\",\"BRCA1\",\"NFKB1\",\"HSPA5\", \"CREBBP\", \"STAT1\", \"STAT3\",\"HIF1A\", \"NFKBIA\",\"JUN\",\"PRKAA1\",\"PDPK1\"],\n",
    "                  #   0      1      2        3        4         5        6       7        8       9      10      11 \n",
    "}\n",
    "\n",
    "output_dir = os.path.join( args['results_dir'], 'scafold_analysis')\n",
    "\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Excape data and compute scafolds\n",
    "Reference data to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Excape = pd.read_csv(args['filename_data_Excape'],index_col=0)\n",
    "data_Excape = data_Excape[ ['Gene_Symbol','SMILES_standard'] ].drop_duplicates()\n",
    "data_Excape = data_Excape.loc[ data_Excape.Gene_Symbol.isin(args[\"Excape_genes\"])].reset_index(drop=True)\n",
    "\n",
    "# Add columns to warn compounds with multiple targets\n",
    "def merge_targets(x):\n",
    "    targets = x.Gene_Symbol.values.astype(str)\n",
    "    if len(targets)>1:\n",
    "        return \";\".join(targets)\n",
    "    else: \n",
    "        return None   \n",
    "multiple_targets = data_Excape.groupby(by='SMILES_standard').apply(lambda x:  merge_targets(x) )\n",
    "multiple_targets = pd.DataFrame(multiple_targets, columns=['multiple_targets']).reset_index()\n",
    "data_Excape = data_Excape.merge(multiple_targets, on='SMILES_standard', how='left')\n",
    "\n",
    "data_Excape['murcko_scafold'] = Parallel(n_jobs=16)(delayed(utils.generate_scaffold)(smiles, generic=False) for smiles in data_Excape.SMILES_standard )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read generated data and compute scafolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - repetition n1\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.92it/s]\n",
      "INFO - repetition n2\n",
      "100%|██████████| 13/13 [00:01<00:00,  8.16it/s]\n",
      "INFO - repetition n3\n",
      "100%|██████████| 13/13 [00:01<00:00,  8.24it/s]\n"
     ]
    }
   ],
   "source": [
    "data_gen_dict = dict()\n",
    "\n",
    "for r, rep in enumerate(args['repetitions']):\n",
    "    logging.info('repetition %s'%rep)\n",
    "    data_gen_dict[r] = pd.DataFrame()\n",
    "    \n",
    "    for gene in tqdm(['DMSO']+ args['Excape_genes']):\n",
    "        \n",
    "        generated_file = os.path.join( args['results_dir'], args[\"generated_ref_dir\"], args[\"generated_ref_filename\"].replace(\"GENE\", gene) ).replace(\"REP\",rep) \n",
    "        temp = pd.read_csv( generated_file, index_col=0 )\n",
    "        \n",
    "        # Compute scafolds if needed and save data with scafolds \n",
    "        if not( 'murcko_scafold' in temp.columns):\n",
    "            temp['murcko_scafold'] = Parallel(n_jobs=16)(delayed(utils.generate_scaffold)(smiles, False) for smiles in temp.SMILES_standard )\n",
    "            temp['murcko_scafold_generic'] = Parallel(n_jobs=16)(delayed(utils.generate_scaffold)(smiles, True) for smiles in temp.SMILES_standard )\n",
    "            temp.to_csv( generated_file )\n",
    "        data_gen_dict[r] = pd.concat( [ data_gen_dict[r], temp ] )\n",
    "    data_gen_dict[r] = data_gen_dict[r].reset_index(drop=True)\n",
    "    \n",
    "data_gen_df = pd.concat( data_gen_dict ).reset_index().drop(columns='level_1').rename(columns={'level_0':'repetition'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Global common scafold quantification between generated and Excape\n",
    "Quantify common scafolds for each gene between generated and Excape agonist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_common_scafolds(df_1, df_2, scafold_col, smiles_col='SMILES_standard'):\n",
    "    \n",
    "    unique_scaf_1 =  df_1[scafold_col].unique()\n",
    "    unique_scaf_2 =  df_2[scafold_col].unique()\n",
    "    \n",
    "    Nscaf_1 = len(unique_scaf_1)\n",
    "    common_idx_1 = df_1[scafold_col].isin( unique_scaf_2 )\n",
    "    Ncommon_scaf_1 = len( df_1.loc[common_idx_1, scafold_col].unique() )\n",
    "    N_comm_scaf_cpds_1 =  len( df_1.loc[common_idx_1, smiles_col].unique() )\n",
    "    \n",
    "    Nscaf_2 = len(unique_scaf_2)\n",
    "    common_idx_2 = df_2[scafold_col].isin( unique_scaf_1 )\n",
    "    Ncommon_scaf_2 = len( df_2.loc[common_idx_2, scafold_col].unique() )\n",
    "    N_comm_scaf_cpds_2 =  len( df_2.loc[common_idx_2, smiles_col].unique() )\n",
    "    \n",
    "    assert Ncommon_scaf_1==Ncommon_scaf_2\n",
    "    \n",
    "    # convert to float so that pandas includes all columns when averaging\n",
    "    Nscaf_1, Nscaf_2, Ncommon_scaf_1, N_comm_scaf_cpds_1, N_comm_scaf_cpds_2 =  float(Nscaf_1), float(Nscaf_2), float(Ncommon_scaf_1), float(N_comm_scaf_cpds_1), float(N_comm_scaf_cpds_2)\n",
    "\n",
    "    return  Nscaf_1, Nscaf_2, Ncommon_scaf_1, N_comm_scaf_cpds_1, N_comm_scaf_cpds_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - File already exists results/scafold_analysis/common_MurkoScafold_quantification_Gene_vs_Excape_mean.csv\n"
     ]
    }
   ],
   "source": [
    "output_filename = os.path.join( output_dir, 'common_MurkoScafold_quantification_Gene_vs_Excape_mean.csv')\n",
    "scafold_col = 'murcko_scafold'\n",
    "\n",
    "if not os.path.isfile(output_filename):\n",
    "    \n",
    "    murkos = dict()    \n",
    "    for r in range(len(args['repetitions'])):\n",
    "        logging.info('repetition %s'%(r+1))\n",
    "        \n",
    "        murkos[r] = pd.DataFrame(columns=['Gene_Symbol_Excape','Gene_Symbol_generated',\n",
    "                                   'N_unique_cpds_Excape','N_unique_cpds_generated',\n",
    "                                   'N_scaf_Excape', 'N_scaf_generated',\n",
    "                                   'N_common_scaf', 'N_cpds_common_scaf_Excape','N_cpds_common_scaf_generated'])\n",
    "\n",
    "        for gene in tqdm(args['Excape_genes']):\n",
    "            \n",
    "            # Select data for current genes\n",
    "            df_excape = data_Excape.loc[ data_Excape.Gene_Symbol == gene, ['SMILES_standard',scafold_col] ] \n",
    "            df_gen = data_gen_dict[r].loc[ data_gen_dict[r].Gene_Symbol == gene, ['SMILES_standard', scafold_col] ]\n",
    "\n",
    "            # Quantify common scafolds\n",
    "            NExcape, Ngen, Ncomm, Ncpds_Excape, Ncpds_gen = quantify_common_scafolds( df_excape, df_gen, scafold_col)\n",
    "            murkos[r].loc[len(murkos[r])] = [ gene, gene, \n",
    "                                             len(df_excape.SMILES_standard.unique() ), len(df_gen.SMILES_standard.unique()), \n",
    "                                             NExcape, Ngen, \n",
    "                                             Ncomm, Ncpds_Excape, Ncpds_gen ]\n",
    "\n",
    "    # Mean among repetitions    \n",
    "    murkos = pd.concat( murkos ).reset_index().rename(columns={'level_0':'repetition'}).drop(columns='level_1')\n",
    "    group_cols = ['Gene_Symbol_Excape','Gene_Symbol_generated','N_unique_cpds_Excape','N_scaf_Excape']\n",
    "    means = murkos.groupby(by=group_cols).mean().drop(columns='repetition').reset_index()\n",
    "    stds = murkos.groupby(by=group_cols).std().drop(columns='repetition').reset_index()\n",
    "    murkos = means.merge(stds, on=group_cols, suffixes=['_mean','_std'])\n",
    "    \n",
    "    # Save results\n",
    "    murkos.to_csv(output_filename)    \n",
    "else:\n",
    "    logging.info('File already exists %s'%output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scafold Enrichment analysis for each gene vs DMSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 perform enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - File already exists. Loading it \n",
      "results/scafold_analysis/SignificantlyEnrichedScafolds_per_gene_vs_DMSO__pValue0.01.pkl\n"
     ]
    }
   ],
   "source": [
    "directionality = ['enriched','reduced'][0]\n",
    "\n",
    "scaf_col = 'murcko_scafold'\n",
    "output_filename = os.path.join( output_dir, 'Significantly'+directionality.capitalize()+'Scafolds_per_gene_vs_DMSO__pValue'+str(args['p-value'])+'.pkl')\n",
    "\n",
    "if not os.path.isfile(output_filename):\n",
    "    \n",
    "    significant_scafolds = dict()\n",
    "    signifcant_p_values = dict()\n",
    "\n",
    "    for r in range(len(args['repetitions'])):\n",
    "        \n",
    "        significant_scafolds[r]= dict()\n",
    "        signifcant_p_values[r] = dict()\n",
    "\n",
    "        rep_data = data_gen_df.loc[ data_gen_df.repetition==r]\n",
    "        counts = rep_data.groupby( by= ['Gene_Symbol','murcko_scafold']).apply(lambda x: len(x.SMILES_standard.unique()))\n",
    "        counts = counts.reset_index().rename(columns={0:\"Unique_SMILES\"})\n",
    "\n",
    "        for gene in  args['Excape_genes']:\n",
    "\n",
    "            gene_df = counts.loc[ counts.Gene_Symbol==gene]\n",
    "            dmso_df = counts.loc[ counts.Gene_Symbol=='DMSO']  \n",
    "            significant_scafolds[r][gene] = []\n",
    "            signifcant_p_values[r][gene] = []\n",
    "            selected_scafolds = gene_df.loc[ gene_df.Unique_SMILES>5, scaf_col].unique() # to reduce time skipping useless scafolds apperaring few times\n",
    "\n",
    "            for scafold in tqdm(selected_scafolds):\n",
    "\n",
    "                # Contingency matrix\n",
    "                cont_mat = pd.DataFrame( index=['scafold_present','scafold_absent'], columns=['cond_gene','cond_dmso'])\n",
    "                cont_mat.loc['scafold_present','cond_gene'] = gene_df.loc[ gene_df[scaf_col]==scafold, 'Unique_SMILES'].sum()  # actually only one element\n",
    "                cont_mat.loc['scafold_absent','cond_gene'] = gene_df.loc[ gene_df[scaf_col]!=scafold, 'Unique_SMILES'].sum()\n",
    "                cont_mat.loc['scafold_present','cond_dmso'] =  dmso_df.loc[ dmso_df[scaf_col]==scafold, 'Unique_SMILES'].sum()\n",
    "                cont_mat.loc['scafold_absent','cond_dmso'] = dmso_df.loc[ dmso_df[scaf_col]!=scafold, 'Unique_SMILES'].sum()\n",
    "                \n",
    "                # Fisher test\n",
    "                _, p = stats.fisher_exact(cont_mat)\n",
    "                significant = (p<args['p-value'])\n",
    "                gene_proportion = cont_mat.loc['scafold_present','cond_gene']/cont_mat.cond_gene.sum()\n",
    "                dmso_proportion  = cont_mat.loc['scafold_present','cond_dmso']/cont_mat.cond_dmso.sum()\n",
    "                \n",
    "                if directionality=='enriched':\n",
    "                    significantly_changed = significant & (gene_proportion >dmso_proportion)\n",
    "                elif directionality=='reduced':\n",
    "                    significantly_changed = significant & (gene_proportion <dmso_proportion)\n",
    "                    \n",
    "                if significantly_changed:\n",
    "                    significant_scafolds[r][gene].append(scafold)\n",
    "                    signifcant_p_values[r][gene].append(str(p))\n",
    "\n",
    "            logging.info(\"rep %i - %s Significant Scafolds: %i\"%(r, gene,len(significant_scafolds[r][gene])))\n",
    "    \n",
    "    # Select scafolds which are consitently enriched in all repetitions\n",
    "    consistent_scafolds = dict()\n",
    "    for gene in significant_scafolds[0].keys():\n",
    "        for r in significant_scafolds.keys():\n",
    "            if r ==0:\n",
    "                common_all_reps = set(significant_scafolds[r][gene])\n",
    "            else:\n",
    "                common_all_reps = common_all_reps.intersection( significant_scafolds[r][gene])\n",
    "        consistent_scafolds[gene] = list(common_all_reps)\n",
    "\n",
    "    # Save Results \n",
    "    scafolds_dict = {'significant_scafolds':significant_scafolds,\n",
    "                 'signifcant_p_values':signifcant_p_values,\n",
    "                 'consistent_scafolds':consistent_scafolds}\n",
    "    pickle.dump(scafolds_dict,  open(output_filename, \"wb\"))\n",
    "\n",
    "else:\n",
    "    logging.info(\"File already exists. Loading it \\n%s\"%output_filename)\n",
    "    scafolds_dict = pickle.load(open(output_filename, \"rb\"))\n",
    "    consistent_scafolds = scafolds_dict['consistent_scafolds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Select large scafolds consistently enriched in all repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - File already exists. Loading it \n",
      "results/scafold_analysis/LargeConsistentlyEnrichedScafolds.pkl\n"
     ]
    }
   ],
   "source": [
    "output_filename = os.path.join( output_dir, 'LargeConsistentlyEnrichedScafolds.pkl')\n",
    "\n",
    "if not os.path.isfile(output_filename):\n",
    "    min_scafold_size = 15\n",
    "    large_consistent_scaf = dict()\n",
    "    for gene in consistent_scafolds.keys():\n",
    "        large_consistent_scaf[gene] = [ s for s in consistent_scafolds[gene] if utils.num_atoms_from_smiles(s)>=min_scafold_size ]\n",
    "    pickle.dump(large_consistent_scaf,  open(output_filename, \"wb\"))\n",
    "else:\n",
    "    logging.info(\"File already exists. Loading it \\n%s\"%output_filename)\n",
    "    large_consistent_scaf = pickle.load(open(output_filename, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find ExCAPE agonists containing large-consistently-enriched scafolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - File already exists \n",
      "results/scafold_analysis/Excape_agonists_with_LargeConsistentlyEnrichedScafolds.csv\n"
     ]
    }
   ],
   "source": [
    "output_filename = os.path.join( output_dir, 'Excape_agonists_with_LargeConsistentlyEnrichedScafolds.csv')\n",
    "if not os.path.isfile(output_filename):\n",
    "    Excape_enriched_scafs = pd.DataFrame()\n",
    "    for gene in args['Excape_genes']:\n",
    "        commom_excape_idx = data_Excape['murcko_scafold'].isin(large_consistent_scaf[gene]) & (data_Excape.Gene_Symbol==gene) \n",
    "        commom_excape = data_Excape.loc[commom_excape_idx].sort_values(by='murcko_scafold').reset_index(drop=True)\n",
    "        commom_excape = commom_excape.rename(columns={'SMILES_standard':'SMILES_standard_Excape'})\n",
    "        commom_excape['Gene_Symbol']=gene\n",
    "        commom_excape['Excape_hit_name']=[ gene+'_#'+str(i+1) for i in range(len(commom_excape))]\n",
    "        Excape_enriched_scafs = pd.concat([Excape_enriched_scafs,commom_excape])\n",
    "    Excape_enriched_scafs = Excape_enriched_scafs.reset_index(drop=True)\n",
    "    Excape_enriched_scafs.to_csv(output_filename)\n",
    "else: \n",
    "    logging.info('File already exists \\n%s'%output_filename)\n",
    "    Excape_enriched_scafs = pd.read_csv(output_filename,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Find generated molecules containing large-consistently-enriched scafolds and with high simmilairty to the corresponding agonist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - \n",
      "-- Gene TP53\n",
      "INFO - TP53 Large-consistently-enriched scafolds: 3\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene BRCA1\n",
      "INFO - BRCA1 Large-consistently-enriched scafolds: 8\n",
      "INFO - of which are found in Excape agonists: 1\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 1\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 1\n",
      "INFO - File already exists\n",
      "INFO - \n",
      "-- Gene NFKB1\n",
      "INFO - NFKB1 Large-consistently-enriched scafolds: 25\n",
      "INFO - of which are found in Excape agonists: 2\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 1\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 1\n",
      "INFO - File already exists\n",
      "INFO - \n",
      "-- Gene HSPA5\n",
      "INFO - HSPA5 Large-consistently-enriched scafolds: 18\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene CREBBP\n",
      "INFO - CREBBP Large-consistently-enriched scafolds: 8\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene STAT1\n",
      "INFO - STAT1 Large-consistently-enriched scafolds: 1\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene STAT3\n",
      "INFO - STAT3 Large-consistently-enriched scafolds: 0\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene HIF1A\n",
      "INFO - HIF1A Large-consistently-enriched scafolds: 3\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene NFKBIA\n",
      "INFO - NFKBIA Large-consistently-enriched scafolds: 33\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene JUN\n",
      "INFO - JUN Large-consistently-enriched scafolds: 1\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene PRKAA1\n",
      "INFO - PRKAA1 Large-consistently-enriched scafolds: 5\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n",
      "INFO - \n",
      "-- Gene PDPK1\n",
      "INFO - PDPK1 Large-consistently-enriched scafolds: 1\n",
      "INFO - of which are found in Excape agonists: 0\n",
      "INFO - of which have generated molecules closed to an Excape agonist: 0\n",
      "INFO - Num Excape agonists with highly simmilar genrated molecules: 0\n"
     ]
    }
   ],
   "source": [
    "for plot_gene in args['Excape_genes']:\n",
    "\n",
    "    output_file = os.path.join(output_dir,'GeneratedMols_with_LargeConsistentlyEnrichedScafolds_and_HighExcapeSim__'+plot_gene+'.csv')\n",
    "    logging.info('\\n-- Gene %s'%(plot_gene))\n",
    "    generated_hits = dict()\n",
    "    scafolds_in_agonists = []\n",
    "    scafolds_with_hits = []\n",
    "    output_hits_df = pd.DataFrame()\n",
    "\n",
    "    for scafold in large_consistent_scaf[plot_gene]:\n",
    "\n",
    "        excape_agonists = data_Excape.loc[ (data_Excape[scaf_col]==scafold) & (data_Excape.Gene_Symbol==plot_gene) ]\n",
    "        if len(excape_agonists)>0:\n",
    "            scafolds_in_agonists.append(scafold)\n",
    "\n",
    "            for Excape_smiles in excape_agonists.SMILES_standard.values:\n",
    "\n",
    "                Excape_ecfp = nn.mol_to_ecfp( nn.smile_to_mol (Excape_smiles)) \n",
    "                generated_mols = data_gen_df.loc[ (data_gen_df.Gene_Symbol==plot_gene) & (data_gen_df[scaf_col]==scafold) ]\n",
    "                generated_mols = pd.DataFrame( generated_mols.SMILES_standard.value_counts().reset_index() ).rename(columns={'index':\"SMILES_standard\",'SMILES_standard':'counts'})\n",
    "                generated_mols['Murcko'] = scafold\n",
    "                generated_mols['Excape_SMILES_standard'] = Excape_smiles\n",
    "                generated_mols[\"ecfp\"]  = nn.smiles_to_ecfps_parallel( generated_mols.SMILES_standard.values )\n",
    "                generated_mols['sim2Excape'] = nn.bulk_dice_sim((Excape_ecfp, generated_mols.ecfp.values))\n",
    "                generated_mols = generated_mols.sort_values(by='sim2Excape', ascending=False)\n",
    "                generated_mols = generated_mols.loc[ generated_mols.sim2Excape>args['ecfp_sim_thresh']].reset_index(drop=True)\n",
    "                output_hits_df = pd.concat([output_hits_df,generated_mols])\n",
    "\n",
    "                if len(generated_mols)>0:\n",
    "                    scafolds_with_hits.append(scafold)\n",
    "                    generated_hits[Excape_smiles] = generated_mols.SMILES_standard.values\n",
    "\n",
    "    # Sumarize results \n",
    "    scafolds_with_hits = np.unique(scafolds_with_hits)\n",
    "    logging.info('%s Large-consistently-enriched scafolds: %i'%(plot_gene,len(large_consistent_scaf[plot_gene])))\n",
    "    logging.info('of which are found in Excape agonists: %i'%(len(scafolds_in_agonists)))\n",
    "    logging.info('of which have generated molecules closed to an Excape agonist: %i'%(len(scafolds_with_hits)))\n",
    "    logging.info('Num Excape agonists with highly simmilar genrated molecules: %i'%(len(generated_hits)))\n",
    "\n",
    "    # Save results \n",
    "    output_hits_df['GeneSymbol']=plot_gene\n",
    "    if len(output_hits_df)>0:\n",
    "        output_hits_df = output_hits_df.drop(columns='ecfp').reset_index(drop=True)\n",
    "        if not os.path.isfile(output_file): \n",
    "            output_hits_df.to_csv(output_file)\n",
    "        else: \n",
    "            logging.info('File already exists')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('cpmolgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c523d9eda279fa4bb4f5cb4e0f9aaca1b2e33fee79d53bba9fa5bcd6fe7fb4f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
